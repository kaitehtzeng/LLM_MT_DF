{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhZOiLibYt9h8JOlP094Wd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaitehtzeng/LLM_MT_DF/blob/main/src/wandb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hTyFb0L0UMW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26382573-5f56-4f92-a999-1e3a48c4622a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.1/300.1 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install wandb -qU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "i9rghy7aVoGU",
        "outputId": "2237cb3e-4020-494d-cf22-eca4c802ce73"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVXni5UcWtpI",
        "outputId": "02690453-64eb-4281-ce46-2b089ccb6346"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dgA9boo9W8JT",
        "outputId": "d004543b-ef40-4ee5-db9a-2185fd735352"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import logging\n",
        "import os\n",
        "from contextlib import nullcontext\n",
        "\n",
        "TRL_USE_RICH = os.environ.get(\"TRL_USE_RICH\", False)\n",
        "\n",
        "from trl.commands.cli_utils import init_zero_verbose, SFTScriptArguments, TrlParser\n",
        "from prompt_temple import formatting_prompts_func,end_of_prompt\n",
        "if TRL_USE_RICH:\n",
        "    init_zero_verbose()\n",
        "    FORMAT = \"%(message)s\"\n",
        "\n",
        "from rich.console import Console\n",
        "from rich.logging import RichHandler\n",
        "\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "\n",
        "from tqdm.rich import tqdm\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import random\n",
        "\n",
        "from trl import (\n",
        "    ModelConfig,\n",
        "    RichProgressCallback,\n",
        "    SFTConfig,\n",
        "    SFTTrainer,\n",
        "    get_peft_config,\n",
        "    get_quantization_config,\n",
        "    get_kbit_device_map,\n",
        "    DataCollatorForCompletionOnlyLM,\n",
        ")\n",
        "from torchtext.data.metrics import bleu_score\n",
        "import wandb\n",
        "\n",
        "wandb.init(project=\"slightly-tuned llma3 model\")\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = \"\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        max_seq_length = 2048,\n",
        "        dtype = fp16,\n",
        "        load_in_4bit = True\n",
        "    )\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "# alpaca_prompt = You MUST copy from above!\n",
        "\n",
        "eval_dataset = load_dataset(\"json\",data_files=eval_file_path)['train']\n",
        "eval_target = [item['tgt'] for item in eval_dataset]\n",
        "eval_dataset = eval_dataset.map(formating_prompts_func_eval,5)\n",
        "\n",
        "def generate_batch(text,model,tokenizer):\n",
        "    input_id = tokenizer(text,return_tensors= pt, padding =True).to(model.device)\n",
        "    output = model.generate(\n",
        "        **input,\n",
        "        max_new_tokens=256,\n",
        "        num_beams=5,\n",
        "        early_stopping=True,\n",
        "        do_sample=False)\n",
        "    mount = []\n",
        "    for input,output_id in zip(input_id['input_ids'],output):\n",
        "        mount.append(output_id[input.size(0):])\n",
        "    tok = tokenizer.batch_decode(mount, skip_special_tokens=True)\n",
        "    return tok\n",
        "\n",
        "\n",
        "def generate_example(dataset,batch_size,model,tokenizer):\n",
        "    ans = []\n",
        "    for i in range(0,len(dataset),5):\n",
        "        batch = generate_batch(data[i:min(len(dataset),i+batch_size)],model,tokenizer)\n",
        "        ans.extend(batch)\n",
        "    return ans\n",
        "\n",
        "result = generate_example(eval_dataset,5,model,tokenizer)\n",
        "\n",
        "result_corpus = [i.split() for i in result]\n",
        "target_corpus = [[i.split()] for i in eval_target]\n",
        "bleu = bleu_score(result_corpus)\n",
        "wandb.log({'bleu':bleu})\n",
        "\n",
        "for i in range(len(eval_dataset)):\n",
        "    wandb.log({'text':eval_dataset[i],'true':eval_target[i],'prediction':result[i]})\n",
        "\n",
        "wandb.finish()\n",
        "\n"
      ],
      "metadata": {
        "id": "7WZ7w9b6WAaN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}